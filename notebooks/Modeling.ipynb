{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "034a8271-0018-41f7-b650-36851e268703",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pendulum\n",
    "import plotly.express as px\n",
    "import ppscore as pps\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn import set_config\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector, TransformedTargetRegressor\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression,ElasticNet\n",
    "from sklearn.metrics import (r2_score,\n",
    "                             root_mean_squared_error,\n",
    "                             mean_absolute_error,\n",
    "                             max_error,\n",
    "                            )\n",
    "from sklearn.model_selection import train_test_split, learning_curve, LearningCurveDisplay\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from ydata_profiling import ProfileReport\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from settings.params import MODEL_PARAMS, SEED\n",
    "from src.make_dataset import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c3774dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'revenue'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_NAME = MODEL_PARAMS[\"TARGET_NAME\"]\n",
    "FEATURES = MODEL_PARAMS[\"DEFAULT_FEATURE_NAMES\"]\n",
    "TARGET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7981b090-3bf5-4cf6-a502-ce04ab23746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data(data_path:str):\n",
    "    data = pd.read_csv(data_path)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data.loc[:, FEATURES],\n",
    "                                                    data[TARGET_NAME],\n",
    "                                                    test_size=MODEL_PARAMS[\"TEST_SIZE\"],\n",
    "                                                    random_state=SEED\n",
    "                                                   )\n",
    "    logger.info(f\"\\nX train: {x_train.shape}\\nY train: {y_train.shape}\\n\"\n",
    "            f\"X test: {x_test.shape}\\nY test: {y_test.shape}\")\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a4f8e89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 15:23:56.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_preprocessed_data\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1m\n",
      "X train: (109, 44)\n",
      "Y train: (109,)\n",
      "X test: (28, 44)\n",
      "Y test: (28,)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load_preprocessed_data(\n",
    "    MODEL_PARAMS[\"DATA_PREPROCESSED_PATH\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af7a3abc-bf8d-47ac-a078-243a63783552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Dict, Any\n",
    "\n",
    "\n",
    "def eval_metrics(y_actual: Union[pd.DataFrame, pd.Series, np.ndarray],\n",
    "                 y_pred: Union[pd.DataFrame, pd.Series, np.ndarray]\n",
    "                 ) -> Dict[str, float]:\n",
    "    \"\"\"Compute evaluation metrics.\n",
    "\n",
    "    Args:\n",
    "        y_actual: Ground truth (correct) target values\n",
    "        y_pred: Estimated target values.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: dictionary of evaluation metrics.\n",
    "            Expected keys are: \"rmse\", \"mae\", \"mape\", \"r2\", \"max_error\"\n",
    "\n",
    "    \"\"\"\n",
    "    # Calculate Root mean squared error, named rmse\n",
    "    rmse = root_mean_squared_error(y_actual, y_pred)\n",
    "    # Calculate mean absolute error, named mae\n",
    "    mae = mean_absolute_error(y_actual, y_pred)\n",
    "    # Calculate R-squared: coefficient of determination, named r2\n",
    "    r2 = r2_score(y_actual, y_pred)\n",
    "    # Calculate max error: maximum value of absolute error (y_actual - y_pred), named maxerror\n",
    "    maxerror = max_error(y_actual, y_pred)\n",
    "    return {\"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "            \"r2\": r2,\n",
    "            \"max_error\": maxerror\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e4b34ab0-aabd-41f3-aae9-7dac670860c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_pipeline(numerical_transformer: list,\n",
    "                    categorical_transformer: list,\n",
    "                    estimator: Pipeline,\n",
    "                    target_transformer: bool=False,\n",
    "                    **kwargs: dict) -> Pipeline:\n",
    "    \"\"\"Define pipeline for modeling.\n",
    "\n",
    "    Args:\n",
    "        numerical_transformer:\n",
    "        categorical_transformer:\n",
    "        target_transformer:\n",
    "        estimator:\n",
    "        kwargs:\n",
    "\n",
    "    Returns:\n",
    "        Pipeline: sklearn pipeline\n",
    "    \"\"\"\n",
    "    numerical_transformer = make_pipeline(*numerical_transformer)\n",
    "\n",
    "    categorical_transformer = make_pipeline(*categorical_transformer)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numerical_transformer, make_column_selector(dtype_include=[\"number\"])),\n",
    "            (\"cat\", categorical_transformer, make_column_selector(dtype_include=[\"object\", \"bool\"])),\n",
    "        ],\n",
    "        remainder=\"drop\",  # non-specified columns are dropped\n",
    "        verbose_feature_names_out=False,  # will not prefix any feature names with the name of the transformer\n",
    "    )\n",
    "    # Append regressor to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    if target_transformer:\n",
    "        model_pipe1 = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                                      (\"estimator\", estimator)])\n",
    "        model_pipe = TransformedTargetRegressor(regressor=model_pipe1,\n",
    "                                                func=np.log,\n",
    "                                                inverse_func=np.exp)\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        model_pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"estimator\", estimator)])\n",
    "        \n",
    "    # logger.info(f\"{model_pipe}\")\n",
    "    return model_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e1f6eb90-9306-4dab-b6c4-672f837a002f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 15:57:02 INFO mlflow.tracking.fluent: Experiment with name 'restaurant_revenue_prediction' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/334374102736216289', creation_time=1723046222304, experiment_id='334374102736216289', last_update_time=1723046222304, lifecycle_stage='active', name='restaurant_revenue_prediction', tags={}>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://localhost:5000\")\n",
    "# Set the tracking experiment (in this case, House Prices is going to be our experiment name)\n",
    "mlflow.set_experiment(\"restaurant_revenue_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "311f614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_path,run_name, estimator,params):\n",
    "    \"\"\"\n",
    "    trained machine learning model and its associated artifacts with MLflow.\n",
    "\n",
    "    Parameters:\n",
    "        run_name (str): Name of the MLflow run.\n",
    "        params (dict): Hyperparameters used for training the model.\n",
    "        model (sklearn.base.BaseEstimator): Trained machine learning model.\n",
    "        of the training dataset.\n",
    "    Returns:\n",
    "        tuple: Trained model instance and evaluation metrics.\n",
    "\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = load_preprocessed_data(data_path)\n",
    "        # Instantiate the model with specified hyperparameters\n",
    "        model_instance =  define_pipeline(numerical_transformer=[SimpleImputer(strategy=\"median\"),\n",
    "                                                     RobustScaler()],\n",
    "                              categorical_transformer=[SimpleImputer(strategy=\"constant\", fill_value=\"undefined\"),\n",
    "                                                       OneHotEncoder(drop=\"if_binary\", handle_unknown=\"ignore\")],\n",
    "                              target_transformer=False,\n",
    "                              estimator=estimator(**params)\n",
    "                         )\n",
    "        model_instance.fit(x_train, y_train)\n",
    "        predictions = model_instance.predict(x_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        metric_eval = eval_metrics(y_test, predictions)\n",
    "\n",
    "        # Log evaluation metrics\n",
    "        mlflow.log_metrics(metric_eval)\n",
    "\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Set a tag to describe the training\n",
    "        mlflow.set_tag(\"Training Info\", \"Basic  model for revenue prediction\")\n",
    "\n",
    "        # Log the trained model\n",
    "        signature = infer_signature(x_train, model_instance.predict(x_train))\n",
    "        model_artifact_path = run_name\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model_instance,\n",
    "            artifact_path=model_artifact_path,\n",
    "            signature=signature,\n",
    "            input_example=x_train,\n",
    "        )\n",
    "\n",
    "        return model_instance, metric_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cdd1c634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 16:22:04.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_preprocessed_data\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1m\n",
      "X train: (109, 44)\n",
      "Y train: (109,)\n",
      "X test: (28, 44)\n",
      "Y test: (28,)\u001b[0m\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('preprocessor',\n",
       "                  ColumnTransformer(transformers=[('num',\n",
       "                                                   Pipeline(steps=[('simpleimputer',\n",
       "                                                                    SimpleImputer(strategy='median')),\n",
       "                                                                   ('robustscaler',\n",
       "                                                                    RobustScaler())]),\n",
       "                                                   <sklearn.compose._column_transformer.make_column_selector object at 0x7f7e2b99bbb0>),\n",
       "                                                  ('cat',\n",
       "                                                   Pipeline(steps=[('simpleimputer',\n",
       "                                                                    SimpleImputer(fill_value='undefined',\n",
       "                                                                                  strategy='constant')),\n",
       "                                                                   ('onehotencoder',\n",
       "                                                                    OneHotEncoder(drop='if_binary',\n",
       "                                                                                  handle_unknown='ignore'))]),\n",
       "                                                   <sklearn.compose._column_transformer.make_column_selector object at 0x7f7e2b99b8e0>)],\n",
       "                                    verbose_feature_names_out=False)),\n",
       "                 ('estimator',\n",
       "                  RandomForestRegressor(max_depth=40, max_features=10,\n",
       "                                        n_estimators=300, n_jobs=-1,\n",
       "                                        random_state=449))]),\n",
       " {'rmse': 3479213.9242209387,\n",
       "  'mae': 2194504.012142857,\n",
       "  'r2': 0.15012975483374125,\n",
       "  'max_error': 13334353.146666666})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train(MODEL_PARAMS[\"DATA_PREPROCESSED_PATH\"],\n",
    "      \"randomForestregressor\",\n",
    "      RandomForestRegressor,\n",
    "      {\"n_estimators\":300, \"max_depth\":40,\"max_features\":10,\"random_state\":449,\"n_jobs\":-1}\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "625e2f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ElasticNet': {'estimator': sklearn.linear_model._coordinate_descent.ElasticNet,\n",
       "  'params': {'alpha': 1.0, 'l1_ratio': 0.5}},\n",
       " 'RandomForestRegressor': {'estimator': sklearn.ensemble._forest.RandomForestRegressor,\n",
       "  'params': {'n_estimators': 30, 'max_depth': 3, 'random_state': 50}},\n",
       " 'GradientBoostingRegressor': {'estimator': sklearn.ensemble._gb.GradientBoostingRegressor,\n",
       "  'params': {'n_estimators': 30,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'random_state': 50}}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define models and parameters to benchmark\n",
    "ESTIMATOR_PARAMS = {ElasticNet.__name__: {\"estimator\": ElasticNet,\n",
    "                                          \"params\": {\"alpha\": 1.0,\n",
    "                                                     \"l1_ratio\": 0.5\n",
    "                                          }\n",
    "                                         },\n",
    "                    RandomForestRegressor.__name__: {\"estimator\": RandomForestRegressor,\n",
    "                                                     \"params\": {\"n_estimators\": 30,\n",
    "                                                                \"max_depth\": 3,\n",
    "                                                                \"random_state\": SEED\n",
    "                                                               }\n",
    "                                             },\n",
    "                    GradientBoostingRegressor.__name__: {\"estimator\": GradientBoostingRegressor,\n",
    "                                                         \"params\": {\"n_estimators\": 30,\n",
    "                                                                    \"learning_rate\": 0.01,\n",
    "                                                                    \"max_depth\": 3,\n",
    "                                                                    \"random_state\": SEED\n",
    "                                                                   }\n",
    "                                                        }\n",
    "}\n",
    "\n",
    "ESTIMATOR_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e918816f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 15:57:49.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_preprocessed_data\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1m\n",
      "X train: (109, 44)\n",
      "Y train: (109,)\n",
      "X test: (28, 44)\n",
      "Y test: (28,)\u001b[0m\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-08-07 15:57:52.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_preprocessed_data\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1m\n",
      "X train: (109, 44)\n",
      "Y train: (109,)\n",
      "X test: (28, 44)\n",
      "Y test: (28,)\u001b[0m\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-08-07 15:57:55.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_preprocessed_data\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1m\n",
      "X train: (109, 44)\n",
      "Y train: (109,)\n",
      "X test: (28, 44)\n",
      "Y test: (28,)\u001b[0m\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Entrainement de plusieurs modeles\n",
    "for model_name, model_configs in ESTIMATOR_PARAMS.items():\n",
    "    estimator = model_configs[\"estimator\"]\n",
    "    params = model_configs[\"params\"]\n",
    "    train(MODEL_PARAMS[\"DATA_PREPROCESSED_PATH\"],\n",
    "      model_name,\n",
    "      estimator,\n",
    "      params\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36193a66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
