{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "034a8271-0018-41f7-b650-36851e268703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfm/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pendulum\n",
    "import plotly.express as px\n",
    "import ppscore as pps\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn import set_config\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector, TransformedTargetRegressor\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, VotingRegressor, GradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.metrics import (r2_score,\n",
    "                             root_mean_squared_error,\n",
    "                             mean_absolute_percentage_error,\n",
    "                             mean_absolute_error,\n",
    "                             max_error,\n",
    "                            )\n",
    "from sklearn.model_selection import train_test_split, learning_curve, LearningCurveDisplay\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from ydata_profiling import ProfileReport\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from settings.params import MODEL_PARAMS, SEED\n",
    "from src.make_dataset import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7981b090-3bf5-4cf6-a502-ce04ab23746d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-04 23:05:54.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.make_dataset\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mDataset lo load from : ../data/train.csv\u001b[0m\n",
      "\u001b[32m2024-08-04 23:05:54.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.make_dataset\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mData shape: (137, 43)\u001b[0m\n",
      "\u001b[32m2024-08-04 23:05:54.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.make_dataset\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mData description:                Id          P1          P2          P3          P4          P5  \\\n",
      "count  137.000000  137.000000  137.000000  137.000000  137.000000  137.000000   \n",
      "mean    68.000000    4.014599    4.408759    4.317518    4.372263    2.007299   \n",
      "std     39.692569    2.910391    1.514900    1.032337    1.016462    1.209620   \n",
      "min      0.000000    1.000000    1.000000    0.000000    3.000000    1.000000   \n",
      "25%     34.000000    2.000000    4.000000    4.000000    4.000000    1.000000   \n",
      "50%     68.000000    3.000000    5.000000    4.000000    4.000000    2.000000   \n",
      "75%    102.000000    4.000000    5.000000    5.000000    5.000000    2.000000   \n",
      "max    136.000000   12.000000    7.500000    7.500000    7.500000    8.000000   \n",
      "\n",
      "               P6          P7          P8          P9  ...         P29  \\\n",
      "count  137.000000  137.000000  137.000000  137.000000  ...  137.000000   \n",
      "mean     3.357664    5.423358    5.153285    5.445255  ...    3.135036   \n",
      "std      2.134235    2.296809    1.858567    1.834793  ...    1.680887   \n",
      "min      1.000000    1.000000    1.000000    4.000000  ...    0.000000   \n",
      "25%      2.000000    5.000000    4.000000    4.000000  ...    2.500000   \n",
      "50%      3.000000    5.000000    5.000000    5.000000  ...    3.000000   \n",
      "75%      4.000000    5.000000    5.000000    5.000000  ...    3.000000   \n",
      "max     10.000000   10.000000   10.000000   10.000000  ...    7.500000   \n",
      "\n",
      "              P30         P31         P32         P33         P34         P35  \\\n",
      "count  137.000000  137.000000  137.000000  137.000000  137.000000  137.000000   \n",
      "mean     2.729927    1.941606    2.525547    1.138686    2.489051    2.029197   \n",
      "std      5.536647    3.512093    5.230117    1.698540    5.165093    3.436272   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      4.000000    3.000000    3.000000    2.000000    3.000000    4.000000   \n",
      "max     25.000000   15.000000   25.000000    6.000000   24.000000   15.000000   \n",
      "\n",
      "              P36         P37       revenue  \n",
      "count  137.000000  137.000000  1.370000e+02  \n",
      "mean     2.211679    1.116788  4.453533e+06  \n",
      "std      4.168211    1.790768  2.576072e+06  \n",
      "min      0.000000    0.000000  1.149870e+06  \n",
      "25%      0.000000    0.000000  2.999068e+06  \n",
      "50%      0.000000    0.000000  3.939804e+06  \n",
      "75%      3.000000    2.000000  5.166635e+06  \n",
      "max     20.000000    8.000000  1.969694e+07  \n",
      "\n",
      "[8 rows x 39 columns]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data = load_data(MODEL_PARAMS[\"TRAIN_PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7a3abc-bf8d-47ac-a078-243a63783552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Dict, Any\n",
    "\n",
    "\n",
    "def eval_metrics(y_actual: Union[pd.DataFrame, pd.Series, np.ndarray],\n",
    "                 y_pred: Union[pd.DataFrame, pd.Series, np.ndarray]\n",
    "                 ) -> Dict[str, float]:\n",
    "    \"\"\"Compute evaluation metrics.\n",
    "\n",
    "    Args:\n",
    "        y_actual: Ground truth (correct) target values\n",
    "        y_pred: Estimated target values.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: dictionary of evaluation metrics.\n",
    "            Expected keys are: \"rmse\", \"mae\", \"mape\", \"r2\", \"max_error\"\n",
    "\n",
    "    \"\"\"\n",
    "    # Calculate Root mean squared error, named rmse\n",
    "    rmse = root_mean_squared_error(y_actual, y_pred)\n",
    "    # Calculate mean absolute error, named mae\n",
    "    mae = mean_absolute_error(y_actual, y_pred)\n",
    "    # Mean absolute percentage error (MAPE)\n",
    "    mape = mean_absolute_percentage_error(y_actual, y_pred)\n",
    "    # Calculate R-squared: coefficient of determination, named r2\n",
    "    r2 = r2_score(y_actual, y_pred)\n",
    "    # Calculate max error: maximum value of absolute error (y_actual - y_pred), named maxerror\n",
    "    maxerror = max_error(y_actual, y_pred)\n",
    "    return {\"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "            \"mape\": mape,\n",
    "            \"r2\": r2,\n",
    "            \"max_error\": maxerror\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b34ab0-aabd-41f3-aae9-7dac670860c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_pipeline(numerical_transformer: list,\n",
    "                    categorical_transformer: list,\n",
    "                    estimator: Pipeline,\n",
    "                    target_transformer: bool=False,\n",
    "                    **kwargs: dict) -> Pipeline:\n",
    "    \"\"\"Define pipeline for modeling.\n",
    "\n",
    "    Args:\n",
    "        numerical_transformer:\n",
    "        categorical_transformer:\n",
    "        target_transformer:\n",
    "        estimator:\n",
    "        kwargs:\n",
    "\n",
    "    Returns:\n",
    "        Pipeline: sklearn pipeline\n",
    "    \"\"\"\n",
    "    numerical_transformer = make_pipeline(*numerical_transformer)\n",
    "\n",
    "    categorical_transformer = make_pipeline(*categorical_transformer)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numerical_transformer, make_column_selector(dtype_include=[\"number\"])),\n",
    "            (\"cat\", categorical_transformer, make_column_selector(dtype_include=[\"object\", \"bool\"])),\n",
    "        ],\n",
    "        remainder=\"drop\",  # non-specified columns are dropped\n",
    "        verbose_feature_names_out=False,  # will not prefix any feature names with the name of the transformer\n",
    "    )\n",
    "    # Append regressor to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    if target_transformer:\n",
    "        model_pipe1 = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                                      (\"estimator\", estimator)])\n",
    "        model_pipe = TransformedTargetRegressor(regressor=model_pipe1,\n",
    "                                                func=np.log,\n",
    "                                                inverse_func=np.exp)\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        model_pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"estimator\", estimator)])\n",
    "        \n",
    "    # logger.info(f\"{model_pipe}\")\n",
    "    return model_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b0ef4-90ef-4dc8-8807-12da5f7d9512",
   "metadata": {},
   "source": [
    "## Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e42305d-9599-4169-83b3-1cf3d824ae68",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Day', 'Month', 'Years', 'Day_Name'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Séparer les données en train et test (25%)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m FEATURES \u001b[38;5;241m=\u001b[39m MODEL_PARAMS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEFAULT_FEATURE_NAMES\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFEATURES\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m      6\u001b[0m                                                     data[TARGET_NAME],\n\u001b[1;32m      7\u001b[0m                                                     test_size\u001b[38;5;241m=\u001b[39mMODEL_PARAMS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTEST_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m                                                     random_state\u001b[38;5;241m=\u001b[39mSEED\n\u001b[1;32m      9\u001b[0m                                                    )\n\u001b[1;32m     11\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mX train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mY train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_test\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mY test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_test\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1256\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[0;32m-> 1256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1430\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1432\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Day', 'Month', 'Years', 'Day_Name'] not in index\""
     ]
    }
   ],
   "source": [
    "# Séparer les données en train et test (25%)\n",
    "\n",
    "FEATURES = MODEL_PARAMS[\"DEFAULT_FEATURE_NAMES\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.loc[:, FEATURES],\n",
    "                                                    data[TARGET_NAME],\n",
    "                                                    test_size=MODEL_PARAMS[\"TEST_SIZE\"],\n",
    "                                                    random_state=SEED\n",
    "                                                   )\n",
    "\n",
    "logger.info(f\"\\nX train: {x_train.shape}\\nY train: {y_train.shape}\\n\"\n",
    "            f\"X test: {x_test.shape}\\nY test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f6eb90-9306-4dab-b6c4-672f837a002f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
