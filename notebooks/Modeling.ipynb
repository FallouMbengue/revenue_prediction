{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "034a8271-0018-41f7-b650-36851e268703",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pendulum\n",
    "import plotly.express as px\n",
    "import ppscore as pps\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn import set_config\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector, TransformedTargetRegressor\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression,ElasticNet\n",
    "from sklearn.metrics import (r2_score,\n",
    "                             root_mean_squared_error,\n",
    "                             mean_absolute_error,\n",
    "                             max_error,\n",
    "                            )\n",
    "from sklearn.model_selection import train_test_split, learning_curve, LearningCurveDisplay\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from ydata_profiling import ProfileReport\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV,LogisticRegression,ElasticNet\n",
    "from sklearn.ensemble import BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from settings.params import MODEL_PARAMS, SEED\n",
    "from src.make_dataset import load_data, date_formatage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b98cf74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'revenue'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_NAME = MODEL_PARAMS[\"TARGET_NAME\"]\n",
    "FEATURES = MODEL_PARAMS[\"DEFAULT_FEATURE_NAMES\"]\n",
    "TARGET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7981b090-3bf5-4cf6-a502-ce04ab23746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data(data_path:str):\n",
    "    data = pd.read_csv(data_path)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data.loc[:, FEATURES],\n",
    "                                                    data[TARGET_NAME],\n",
    "                                                    test_size=MODEL_PARAMS[\"TEST_SIZE\"],\n",
    "                                                    random_state=SEED\n",
    "                                                   )\n",
    "    logger.info(f\"\\nX train: {x_train.shape}\\nY train: {y_train.shape}\\n\"\n",
    "            f\"X test: {x_test.shape}\\nY test: {y_test.shape}\")\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84d33dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 15:23:56.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_preprocessed_data\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1m\n",
      "X train: (109, 44)\n",
      "Y train: (109,)\n",
      "X test: (28, 44)\n",
      "Y test: (28,)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load_preprocessed_data(\n",
    "    MODEL_PARAMS[\"DATA_PREPROCESSED_PATH\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af7a3abc-bf8d-47ac-a078-243a63783552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Dict, Any\n",
    "\n",
    "\n",
    "def eval_metrics(y_actual: Union[pd.DataFrame, pd.Series, np.ndarray],\n",
    "                 y_pred: Union[pd.DataFrame, pd.Series, np.ndarray]\n",
    "                 ) -> Dict[str, float]:\n",
    "    \"\"\"Compute evaluation metrics.\n",
    "\n",
    "    Args:\n",
    "        y_actual: Ground truth (correct) target values\n",
    "        y_pred: Estimated target values.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: dictionary of evaluation metrics.\n",
    "            Expected keys are: \"rmse\", \"mae\", \"mape\", \"r2\", \"max_error\"\n",
    "\n",
    "    \"\"\"\n",
    "    # Calculate Root mean squared error, named rmse\n",
    "    rmse = root_mean_squared_error(y_actual, y_pred)\n",
    "    # Calculate mean absolute error, named mae\n",
    "    mae = mean_absolute_error(y_actual, y_pred)\n",
    "    # Calculate R-squared: coefficient of determination, named r2\n",
    "    r2 = r2_score(y_actual, y_pred)\n",
    "    # Calculate max error: maximum value of absolute error (y_actual - y_pred), named maxerror\n",
    "    maxerror = max_error(y_actual, y_pred)\n",
    "    return {\"rmse\": rmse,\n",
    "            \"mae\": mae,\n",
    "            \"r2\": r2,\n",
    "            \"max_error\": maxerror\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e4b34ab0-aabd-41f3-aae9-7dac670860c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_pipeline(numerical_transformer: list,\n",
    "                    categorical_transformer: list,\n",
    "                    estimator: Pipeline,\n",
    "                    target_transformer: bool=False,\n",
    "                    **kwargs: dict) -> Pipeline:\n",
    "    \"\"\"Define pipeline for modeling.\n",
    "\n",
    "    Args:\n",
    "        numerical_transformer:\n",
    "        categorical_transformer:\n",
    "        target_transformer:\n",
    "        estimator:\n",
    "        kwargs:\n",
    "\n",
    "    Returns:\n",
    "        Pipeline: sklearn pipeline\n",
    "    \"\"\"\n",
    "    numerical_transformer = make_pipeline(*numerical_transformer)\n",
    "\n",
    "    categorical_transformer = make_pipeline(*categorical_transformer)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numerical_transformer, make_column_selector(dtype_include=[\"number\"])),\n",
    "            (\"cat\", categorical_transformer, make_column_selector(dtype_include=[\"object\", \"bool\"])),\n",
    "        ],\n",
    "        remainder=\"drop\",  # non-specified columns are dropped\n",
    "        verbose_feature_names_out=False,  # will not prefix any feature names with the name of the transformer\n",
    "    )\n",
    "    # Append regressor to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    if target_transformer:\n",
    "        model_pipe1 = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                                      (\"estimator\", estimator)])\n",
    "        model_pipe = TransformedTargetRegressor(regressor=model_pipe1,\n",
    "                                                func=np.log,\n",
    "                                                inverse_func=np.exp)\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        model_pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"estimator\", estimator)])\n",
    "        \n",
    "    # logger.info(f\"{model_pipe}\")\n",
    "    return model_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e1f6eb90-9306-4dab-b6c4-672f837a002f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 15:57:02 INFO mlflow.tracking.fluent: Experiment with name 'restaurant_revenue_prediction' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/334374102736216289', creation_time=1723046222304, experiment_id='334374102736216289', last_update_time=1723046222304, lifecycle_stage='active', name='restaurant_revenue_prediction', tags={}>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://localhost:5000\")\n",
    "# Set the tracking experiment (in this case, House Prices is going to be our experiment name)\n",
    "mlflow.set_experiment(\"restaurant_revenue_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5893dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_path,run_name, estimator,params):\n",
    "    \"\"\"\n",
    "    trained machine learning model and its associated artifacts with MLflow.\n",
    "\n",
    "    Parameters:\n",
    "        run_name (str): Name of the MLflow run.\n",
    "        params (dict): Hyperparameters used for training the model.\n",
    "        model (sklearn.base.BaseEstimator): Trained machine learning model.\n",
    "        of the training dataset.\n",
    "    Returns:\n",
    "        tuple: Trained model instance and evaluation metrics.\n",
    "\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = load_preprocessed_data(data_path)\n",
    "        # Instantiate the model with specified hyperparameters\n",
    "        model_instance =  define_pipeline(numerical_transformer=[SimpleImputer(strategy=\"median\"),\n",
    "                                                     RobustScaler()],\n",
    "                              categorical_transformer=[SimpleImputer(strategy=\"constant\", fill_value=\"undefined\"),\n",
    "                                                       OneHotEncoder(drop=\"if_binary\", handle_unknown=\"ignore\")],\n",
    "                              target_transformer=False,\n",
    "                              estimator=estimator(**params)\n",
    "                         )\n",
    "        model_instance.fit(x_train, y_train)\n",
    "        predictions = model_instance.predict(x_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        metric_eval = eval_metrics(y_test, predictions)\n",
    "\n",
    "        # Log evaluation metrics\n",
    "        mlflow.log_metrics(metric_eval)\n",
    "\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Set a tag to describe the training\n",
    "        mlflow.set_tag(\"Training Info\", \"Basic  model for revenue prediction\")\n",
    "\n",
    "        # Log the trained model\n",
    "        signature = infer_signature(x_train, model_instance.predict(x_train))\n",
    "        model_artifact_path = run_name\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model_instance,\n",
    "            artifact_path=model_artifact_path,\n",
    "            signature=signature,\n",
    "            input_example=x_train,\n",
    "        )\n",
    "\n",
    "        return model_instance, metric_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4aeaf8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 21:19:04.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_preprocessed_data\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1m\n",
      "X train: (109, 44)\n",
      "Y train: (109,)\n",
      "X test: (28, 44)\n",
      "Y test: (28,)\u001b[0m\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('preprocessor',\n",
       "                  ColumnTransformer(transformers=[('num',\n",
       "                                                   Pipeline(steps=[('simpleimputer',\n",
       "                                                                    SimpleImputer(strategy='median')),\n",
       "                                                                   ('robustscaler',\n",
       "                                                                    RobustScaler())]),\n",
       "                                                   <sklearn.compose._column_transformer.make_column_selector object at 0x7f7e147dee00>),\n",
       "                                                  ('cat',\n",
       "                                                   Pipeline(steps=[('simpleimputer',\n",
       "                                                                    SimpleImputer(fill_value='undefined',\n",
       "                                                                                  strategy='constant'...\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=10, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=200, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=None, ...))]),\n",
       " {'rmse': 4232433.582259157,\n",
       "  'mae': 2535566.5089285714,\n",
       "  'r2': -0.2576814696203016,\n",
       "  'max_error': 13200869.0})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train(MODEL_PARAMS[\"DATA_PREPROCESSED_PATH\"],\n",
    "      XGBRegressor.__name__,\n",
    "      XGBRegressor,\n",
    "      {\"n_estimators\":200,\n",
    "       \"learning_rate\":0.1,\n",
    "       \"max_depth\":10\n",
    "      }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ccf1a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ElasticNet': {'estimator': sklearn.linear_model._coordinate_descent.ElasticNet,\n",
       "  'params': {'alpha': 1.0, 'l1_ratio': 0.5}},\n",
       " 'RandomForestRegressor': {'estimator': sklearn.ensemble._forest.RandomForestRegressor,\n",
       "  'params': {'n_estimators': 30, 'max_depth': 3, 'random_state': 50}},\n",
       " 'GradientBoostingRegressor': {'estimator': sklearn.ensemble._gb.GradientBoostingRegressor,\n",
       "  'params': {'n_estimators': 30,\n",
       "   'learning_rate': 0.01,\n",
       "   'max_depth': 3,\n",
       "   'random_state': 50}}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define models and parameters to benchmark\n",
    "ESTIMATOR_PARAMS = {ElasticNet.__name__: {\"estimator\": ElasticNet,\n",
    "                                          \"params\": {\"alpha\": 1.0,\n",
    "                                                     \"l1_ratio\": 0.5\n",
    "                                          }\n",
    "                                         },\n",
    "                    RandomForestRegressor.__name__: {\"estimator\": RandomForestRegressor,\n",
    "                                                     \"params\": {\"n_estimators\": 30,\n",
    "                                                                \"max_depth\": 3,\n",
    "                                                                \"random_state\": SEED\n",
    "                                                               }\n",
    "                                             },\n",
    "                    GradientBoostingRegressor.__name__: {\"estimator\": GradientBoostingRegressor,\n",
    "                                                         \"params\": {\"n_estimators\": 30,\n",
    "                                                                    \"learning_rate\": 0.01,\n",
    "                                                                    \"max_depth\": 3,\n",
    "                                                                    \"random_state\": SEED\n",
    "                                                                   }\n",
    "                                                        }\n",
    "}\n",
    "\n",
    "ESTIMATOR_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4454d851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 15:57:49.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_preprocessed_data\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1m\n",
      "X train: (109, 44)\n",
      "Y train: (109,)\n",
      "X test: (28, 44)\n",
      "Y test: (28,)\u001b[0m\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-08-07 15:57:52.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_preprocessed_data\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1m\n",
      "X train: (109, 44)\n",
      "Y train: (109,)\n",
      "X test: (28, 44)\n",
      "Y test: (28,)\u001b[0m\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-08-07 15:57:55.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_preprocessed_data\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1m\n",
      "X train: (109, 44)\n",
      "Y train: (109,)\n",
      "X test: (28, 44)\n",
      "Y test: (28,)\u001b[0m\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/user/anaconda3/lib/python3.10/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Entrainement de plusieurs modeles\n",
    "for model_name, model_configs in ESTIMATOR_PARAMS.items():\n",
    "    estimator = model_configs[\"estimator\"]\n",
    "    params = model_configs[\"params\"]\n",
    "    train(MODEL_PARAMS[\"DATA_PREPROCESSED_PATH\"],\n",
    "      model_name,\n",
    "      estimator,\n",
    "      params\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ca415d",
   "metadata": {},
   "source": [
    "### test dataset prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5de1617d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 21:55:16.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.make_dataset\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mDataset lo load from : ../data/test.csv\u001b[0m\n",
      "\u001b[32m2024-08-07 21:55:16.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.make_dataset\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mData shape: (100000, 42)\u001b[0m\n",
      "\u001b[32m2024-08-07 21:55:16.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.make_dataset\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mData description:                   Id             P1             P2             P3  \\\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
      "mean    49999.500000       4.088030       4.428085       4.215325   \n",
      "std     28867.657797       2.812963       1.428865       0.842161   \n",
      "min         0.000000       1.000000       1.000000       0.000000   \n",
      "25%     24999.750000       2.000000       3.750000       4.000000   \n",
      "50%     49999.500000       3.000000       5.000000       4.000000   \n",
      "75%     74999.250000       4.000000       5.000000       4.000000   \n",
      "max     99999.000000      15.000000       7.500000       6.000000   \n",
      "\n",
      "                  P4             P5             P6            P7  \\\n",
      "count  100000.000000  100000.000000  100000.000000  100000.00000   \n",
      "mean        4.396025       1.989590       2.881900       5.30051   \n",
      "std         1.035827       1.065314       1.531429       2.17858   \n",
      "min         2.000000       1.000000       1.000000       1.00000   \n",
      "25%         4.000000       1.000000       2.000000       5.00000   \n",
      "50%         4.000000       2.000000       2.000000       5.00000   \n",
      "75%         5.000000       2.000000       4.000000       5.00000   \n",
      "max         7.500000       6.000000      10.000000      10.00000   \n",
      "\n",
      "                 P8             P9  ...            P28            P29  \\\n",
      "count  100000.00000  100000.000000  ...  100000.000000  100000.000000   \n",
      "mean        4.93100       5.251380  ...       3.233785       3.084000   \n",
      "std         1.71849       1.702632  ...       2.136694       1.783927   \n",
      "min         1.00000       4.000000  ...       1.000000       0.000000   \n",
      "25%         4.00000       4.000000  ...       2.000000       2.000000   \n",
      "50%         5.00000       5.000000  ...       3.000000       3.000000   \n",
      "75%         5.00000       5.000000  ...       4.000000       3.000000   \n",
      "max        10.00000      10.000000  ...      12.500000      10.000000   \n",
      "\n",
      "                 P30            P31            P32            P33  \\\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
      "mean        2.083300       1.193330       1.942640       0.987430   \n",
      "std         4.309479       2.307944       3.971298       1.534808   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         3.000000       1.000000       3.000000       2.000000   \n",
      "max        25.000000      15.000000      25.000000       6.000000   \n",
      "\n",
      "                 P34            P35            P36            P37  \n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000  \n",
      "mean        2.108670       1.832830       1.968890       0.973500  \n",
      "std         4.685414       3.228769       3.805773       1.677267  \n",
      "min         0.000000       0.000000       0.000000       0.000000  \n",
      "25%         0.000000       0.000000       0.000000       0.000000  \n",
      "50%         0.000000       0.000000       0.000000       0.000000  \n",
      "75%         3.000000       4.000000       3.000000       2.000000  \n",
      "max        30.000000      15.000000      20.000000       8.000000  \n",
      "\n",
      "[8 rows x 38 columns]\u001b[0m\n",
      "\u001b[32m2024-08-07 21:55:16.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.make_dataset\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mColumns will be transformed to lower!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_data = load_data(MODEL_PARAMS[\"TEST_PATH\"], columns_to_lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c2a8e90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>city</th>\n",
       "      <th>city group</th>\n",
       "      <th>type</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>...</th>\n",
       "      <th>p32</th>\n",
       "      <th>p33</th>\n",
       "      <th>p34</th>\n",
       "      <th>p35</th>\n",
       "      <th>p36</th>\n",
       "      <th>p37</th>\n",
       "      <th>day</th>\n",
       "      <th>day_name</th>\n",
       "      <th>month</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Niğde</td>\n",
       "      <td>Other</td>\n",
       "      <td>FC</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Konya</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>Friday</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>FC</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Kocaeli</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Monday</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Afyonkarahisar</td>\n",
       "      <td>Other</td>\n",
       "      <td>FC</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99995</td>\n",
       "      <td>Antalya</td>\n",
       "      <td>Other</td>\n",
       "      <td>FC</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99996</td>\n",
       "      <td>Niğde</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>Monday</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99997</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>IL</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>12</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99998</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>FC</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>99999</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>IL</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>10</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id            city  city group type  p1   p2   p3   p4  p5  p6  ...  \\\n",
       "0          0           Niğde       Other   FC   1  4.0  4.0  4.0   1   2  ...   \n",
       "1          1           Konya       Other   IL   3  4.0  4.0  4.0   2   2  ...   \n",
       "2          2          Ankara  Big Cities   FC   3  4.0  4.0  4.0   2   2  ...   \n",
       "3          3         Kocaeli       Other   IL   2  4.0  4.0  4.0   2   3  ...   \n",
       "4          4  Afyonkarahisar       Other   FC   2  4.0  4.0  4.0   1   2  ...   \n",
       "...      ...             ...         ...  ...  ..  ...  ...  ...  ..  ..  ...   \n",
       "99995  99995         Antalya       Other   FC   5  5.0  4.0  4.0   2   2  ...   \n",
       "99996  99996           Niğde       Other   IL   1  2.0  4.0  3.0   1   1  ...   \n",
       "99997  99997        İstanbul  Big Cities   IL   4  5.0  4.0  4.0   1   2  ...   \n",
       "99998  99998        İstanbul  Big Cities   FC  12  7.5  6.0  6.0   4   4  ...   \n",
       "99999  99999        İstanbul  Big Cities   IL   2  5.0  4.0  4.0   2   2  ...   \n",
       "\n",
       "       p32  p33  p34  p35  p36  p37  day   day_name  month  years  \n",
       "0        0    0    0    0    0    0   22   Saturday      1   2011  \n",
       "1        0    0    0    0    0    0   18     Friday      3   2011  \n",
       "2        0    0    0    0    0    0   30  Wednesday     10   2013  \n",
       "3        0    0    0    0    0    0    6     Monday      5   2013  \n",
       "4        0    0    0    0    0    0   31  Wednesday      7   2013  \n",
       "...    ...  ...  ...  ...  ...  ...  ...        ...    ...    ...  \n",
       "99995    0    0    0    0    0    0    5  Wednesday      1   2000  \n",
       "99996    0    0    4    0    0    0   18     Monday      7   2011  \n",
       "99997    3    2    4    4    4    2   29   Saturday     12   2012  \n",
       "99998    0    4    0    0    0    0   12   Saturday     10   2013  \n",
       "99999    0    2    2    4    2    0    5    Tuesday     10   2010  \n",
       "\n",
       "[100000 rows x 45 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = date_formatage(test_data)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d75e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test_data[\"id\"]\n",
    "test_data.drop(\"id\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "be70674c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37527f86716e45169b2a24aaff629c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "# Spécifie le chemin du modèle enregistré\n",
    "logged_model = 'runs:/16bf593f34ed4d42bbf04db25f816b53/randomForestregressor'\n",
    "\n",
    "# Charger le modèle en tant que PyFuncModel\n",
    "model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "858ff8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "Prediction = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "49767e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.550099e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.610265e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.238604e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.746265e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.690135e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99995</td>\n",
       "      <td>4.993735e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99996</td>\n",
       "      <td>2.907670e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99997</td>\n",
       "      <td>4.832232e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99998</td>\n",
       "      <td>4.722116e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>99999</td>\n",
       "      <td>4.600332e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    Prediction\n",
       "0          0  4.550099e+06\n",
       "1          1  3.610265e+06\n",
       "2          2  4.238604e+06\n",
       "3          3  3.746265e+06\n",
       "4          4  4.690135e+06\n",
       "...      ...           ...\n",
       "99995  99995  4.993735e+06\n",
       "99996  99996  2.907670e+06\n",
       "99997  99997  4.832232e+06\n",
       "99998  99998  4.722116e+06\n",
       "99999  99999  4.600332e+06\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join prediction dataframe with ids\n",
    "Predictions = pd.DataFrame({\"id\":ids,\"Prediction\":Prediction})\n",
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17078c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the predictions\n",
    "Predictions.to_csv(MODEL_PARAMS[\"PREDICTION_PATH\"],index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
